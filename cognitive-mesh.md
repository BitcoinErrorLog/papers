# Cognitive Sovereignty Mesh: Toward a Decentralized Epistemic Infrastructure

## Introduction  
In an age of information overload and algorithmic feeds, individuals increasingly seek control over their digital identities, trust relationships, and cognitive processes. Centralized platforms currently mediate much of our knowledge and social trust, often at the expense of personal autonomy and truth discernment. This paper proposes a new paradigm – a **Cognitive Sovereignty Mesh** – as a foundational “epistemic substrate” for the web. It integrates concepts of self-sovereign identity, semantic tagging of information, personal trust networks, and AI agents tailored to individual worldviews. The approach builds on diverse precursors from philosophy and technology: the *Extended Mind* thesis (which holds that tools and environment can become part of cognition ([The Extended Mind | Books Gateway - MIT Press Direct](https://direct.mit.edu/books/edited-volume/2362/The-Extended-Mind#:~:text=The%20Extended%20Mind%20,role%20in%20driving%20cognition))), *Computational Trust* models in multi-agent systems ([Stephen (Steve) Marsh | Ontario Tech University](https://ontariotechu.ca/experts/fbit/stephen-marsh.php#:~:text=Stephen%20%28Steve%29%20Marsh%20,of%20research%20in%20computational%20trust)), the *Subjective Web of Trust* in decentralized moderation ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)), PGP’s *Web of Trust*, distributional semantics (e.g. *Word2Vec* embeddings that learn meaning from context ([Demystifying Word Vectors - DEV Community](https://dev.to/jbahire/demystifying-word-vectors-50pj#:~:text=Demystifying%20Word%20Vectors%20,The%20context))), and early visions like the 2003 *Augmented Social Network* proposal for identity and trust layers on the Internet ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=This%20paper%20proposes%20the%20creation,to%20better%20engage%20in%20the)). Bringing these threads together, we outline a system of **semantic tagging** (as an externalization of users’ mental models), **weighted tagging and composable trust graphs** (to capture nuance and personal relationships), **decentralized key-based identity** (using systems like *Pubky*), **atomic trust-based credit** (peer-to-peer economic exchange grounded in trust), and **AI agents** co-trained on personal semantic graphs. Guiding values – pluralism of perspectives, system legibility, and user cognitive sovereignty – shape the design at every layer. We frame the Cognitive Sovereignty Mesh as a new kind of cognitive infrastructure that empowers individuals and communities to manage knowledge, trust, and AI on their own terms. 

The paper is structured in a layered, tutorial manner. We begin with foundational concepts: identity, trust, mental models, and guiding principles. We then detail the system architecture (the Pubky identity backbone, semantic graph structures, trust network mechanics, and AI integration). Finally, we explore speculative implications of this approach, from AI alignment strategies to new forms of social organization. Throughout, we draw parallels to prior research and propose updated terminology (for example, refining the notion of “bandwidth economics” in light of related work on the attention economy). The goal is an interdisciplinary understanding of a **“Cognitive Sovereignty Mesh”** – a resilient mesh of people and AI co-creating an open, personalized web of knowledge and trust.

## Foundations of Identity, Trust, and Mental Models

### Decentralized Identity and Self-Sovereignty  
A first pillar of the envisioned system is **self-sovereign identity**. Traditional online identities (usernames, profiles) depend on platforms or certificate authorities, which can censor or silo users. By contrast, a key-based identity system empowers individuals to own and control their identifiers using cryptographic keys. One example is *Pubky*, a protocol using public–private key pairs as identities, akin to how Bitcoin or Nostr identify users by keys. Pubky goes further by leveraging a distributed hash table (DHT) for decentralized lookup of identity data. It uses *Public Key Addressable Resource Records (PKARR)* and *Public Key DNS (PKDNS)* to map public keys to data (profiles, content) without relying on centralized DNS ([Mainline DHT — Censorship Resistance Explained | by Severin Alexander Bühler | Pubky | Dec, 2024 | Medium | Pubky](https://medium.com/pubky/mainline-dht-censorship-explained-b62763db39cb#:~:text=At%20Synonym%2C%20we%20created%20PKARR,to%20censorship%20and%20central%20control)). In essence, every public key can function like a self-hosted domain name, discoverable through a large peer-to-peer network (the BitTorrent Mainline DHT). This means *each user’s identity can have an uncensorable “home” on the network, free from takedowns or gatekeepers, with data stored redundantly across a massive swarm of nodes* ([Add Pubky Integration · Issue #1548 · nostr-protocol/nips · GitHub](https://github.com/nostr-protocol/nips/issues/1548#:~:text=It%20has%20also%20been%20integrated,tracking%20DNS%20server)). 

Such a decentralized identity layer establishes a foundation of persistence and portability. A user can “log in” to any supporting application with their cryptographic key, proving who they are without a central authority. Because identity data (such as profile information, social links, or reputation attestations) can be associated with the key via the DHT, the user carries their social presence with them. If one platform bans or blocks them, they can reappear elsewhere, reconstructing their social graph and content from the open network ([Introducing Pubky, a comprehensive solution for fixing the web, from Synonym \ stacker news ~nostr](https://stacker.news/items/741757#:~:text=On%20the%20tech%20side%2C%20you,left%20off%20from%20another%20server)) ([Introducing Pubky, a comprehensive solution for fixing the web, from Synonym \ stacker news ~nostr](https://stacker.news/items/741757#:~:text=On%20the%20tech%20side%2C%20you,left%20off%20from%20another%20server)). This property is crucial for *cognitive sovereignty*: the continuity of one’s identity and data is under the user’s control, not a company’s whims.

Decentralized identity also lays the groundwork for trust. In PGP’s classic Web of Trust, public keys are bound to real-world identities via certificates that friends sign, creating a distributed trust network ([Web of trust - Wikipedia](https://en.wikipedia.org/wiki/Web_of_trust#:~:text=A%20web%20of%20trust%20is,public%20key%20and%20its)). The principle is that *authentication and reputation can be established through a mesh of peer endorsements rather than a central certificate authority*. The Cognitive Sovereignty Mesh generalizes this—public keys are not only identifiers but anchors for *all kinds of attestations*: you could attest “Alice’s key is owned by Alice (personal identity verification)”, or “Alice’s key has expertise in cryptography”, or even subjective statements like “I trust Alice’s movie reviews”. The **self-sovereign identity** framework ensures these attestations are tied to user-controlled keys, enabling a rich tapestry of reputation and trust data to accumulate in a decentralized way. In summary, a key-based identity system like Pubky provides the *who* in our system – a stable, user-owned identity – which is a prerequisite to attach the *what* (tags, content) and *how* (trust levels, reputations) that we discuss next.

### Trust Networks and the Web of Trust Tradition  
**Trust** is the glue that binds a decentralized social system together. In face-to-face communities, trust is nuanced and contextual – we trust different people for different tasks or knowledge domains. Capturing this online requires moving beyond binary trust/no-trust models towards *computational trust metrics* that are quantitative and subjective. Stephen Marsh’s pioneering 1994 thesis introduced the idea that trust can be formalized as a computable value that agents use in decision-making ([Stephen (Steve) Marsh | Ontario Tech University](https://ontariotechu.ca/experts/fbit/stephen-marsh.php#:~:text=Stephen%20%28Steve%29%20Marsh%20,of%20research%20in%20computational%20trust)). Since then, numerous models (from simple rating systems to sophisticated graph algorithms) have sought to represent how trust propagates in networks. A key insight is that trust is **propagative and composable**: if Alice trusts Bob, and Bob trusts Carol, there is a basis (though not certainty) for Alice to somewhat trust Carol. This transitivity means trust relationships form a graph that algorithms can traverse or aggregate. For example, the *EigenTrust* algorithm (2003) computes global reputation by iteratively aggregating local trust scores along the links of a peer-to-peer network ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)). Recent research with graph neural networks also leverages the “propagative and composable nature of trust graphs” to evaluate trust in social networks ([TrustGNN: Graph Neural Network-Based Trust Evaluation via ...](https://ieeexplore.ieee.org/document/10137371/#:~:text=,graphs%20into%20a%20GNN)).

In our Cognitive Sovereignty Mesh, each user maintains a **personal trust graph** – a network of other identities (public keys) that they trust, distrust, or anything in between. Importantly, trust here is *weighted*. Rather than a blanket statement of trust, a user can express degrees of confidence. (Not unlike PGP’s model where one can mark a key’s trust level as “full”, “marginal”, or “untrusted” ([PGP Web of Trust: Delegated Trust and Keyservers - Linux Foundation](https://www.linuxfoundation.org/blog/blog/pgp-web-of-trust-delegated-trust-and-keyservers#:~:text=PGP%20Web%20of%20Trust%3A%20Delegated,marginally%20trusted%20keys%20to)).) For instance, you might assign Alice a trust score of 0.9 in the context of software advice, but only 0.4 for political news – reflecting your experience of her reliability in those domains. These weights are subjective and set by each user, hence forming a **subjective web of trust**. There is no single global reputation score; instead, *each participant effectively computes their own view of who is trustworthy* based on their direct ratings and the extended network of recommendations. This resonates with the idea of a “purely subjective web of trust” as a starting point for reputation systems ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)) – each person begins with their personal opinions before any global consensus emerges.

Trust graphs are **composable** in the sense that one can incorporate others’ trust stances. If you deeply trust Bob, you might choose to import Bob’s trust ratings of others into your own calculations (perhaps with some discount). This allows *clusters of trust* to interconnect: friends and communities can share trust data to form a more robust collective filter. Mechanisms could be built so that users publish signed attestations like “I trust X with weight Y”, which others can subscribe to. Composability also means specialized trust networks (for example, a network of medical professionals vouching for each other’s credentials) can plug into a person’s broader trust graph when relevant (e.g. when seeking health information). All of this remains under user control – the user decides whose attestation to accept or how to weight them. The mathematics of trust propagation (path weighting, decay with distance, etc.) can draw on extensive prior literature ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)), but always anchored in a *first-person perspective*. In effect, the system creates a **Web of Trust** generalized beyond cryptographic key validity and into the realm of content credibility and social reputation, all while preserving the *subjectivity* and nuance of real trust relationships.

Critically, a trust-based approach to information helps manage the deluge of online content. Each user’s personal trust graph becomes a filter for information relevance and truth. Posts or data from unknown parties get de-prioritized or flagged unless they come via a chain of trust from known peers. This can dramatically increase signal-to-noise ratio in one’s information diet. The absence of a single authoritative filter (like a centralized algorithmic feed) is compensated by a *network of human judgments*, which tends to be more difficult for malicious actors to game at scale. Even if disinformation enters the network, it may not travel far unless it can hop through trust links – and those links represent hard-earned social capital. In summary, the trust network provides a **human-centered filter** on information, externalizing the age-old social process of “consider the source” into a tangible data structure that software agents can use on behalf of the user.

### Mental Models, Semantic Tagging, and Externalized Knowledge  
If trust graphs represent *who* we rely on, **semantic tagging** represents *how we make sense of the world*. Humans internalize knowledge as mental models – frameworks of concepts and relationships that help us interpret new information. Traditionally, these mental models stay mostly in our heads, but they can be *externalized* through language, writing, and categorization. The act of tagging or categorizing information is effectively *mapping one’s mental model onto external artifacts*. For example, when you tag an article as “climate science”, “trustworthy”, or “speculative”, you are projecting your mental categorization onto that piece of content. This not only helps you remember or retrieve it later, it also shares a bit of your perspective with others.

The idea that tools can function as part of cognition is captured by Clark and Chalmers’ *Extended Mind* hypothesis. They argue that elements of the environment (a notebook, a computer) can serve as extensions of our mind if we rely on them in cognitive processes ([The Extended Mind | Books Gateway - MIT Press Direct](https://direct.mit.edu/books/edited-volume/2362/The-Extended-Mind#:~:text=The%20Extended%20Mind%20,role%20in%20driving%20cognition)). Semantic tagging is a clear example: a personal tagging system can serve as an extension of human memory and understanding. One might recall that “I tagged a study under *climate science* and *reliable* last month” – effectively outsourcing some memory to the tag system, which in turn cues one’s internal knowledge when revisited. In the Cognitive Sovereignty Mesh, **semantic tagging** is elevated to a first-class activity. Users label not just articles or bookmarks, but potentially people, ideas, and even their own AI agent’s behaviors, in a consistent semantic graph. Over time, each user builds a **personal semantic graph**: a network of tags (concepts, themes, values) and the connections to resources or entities those tags describe. This is akin to a personal ontology or mind-map that grows with one’s learning.

A crucial enhancement is **weighted tagging**. Just as trust was not binary, tags can have strengths or scores. Perhaps you tag a source “bias: 0.8 conservative” or an article “importance: 5 (out of 5)”. This introduces gradation in your externalized mental model. It also complements the trust model – e.g., you might tag a friend “expertise: AI/ML” to note that you defer to them on that topic. Together, weighted tags and trust graphs form a rich semantic structure that encodes both *what* information means to you and *who* you consider credible about it. These graphs are personal, but they can align or interoperate socially. If many people use similar tags, a folksonomy emerges (a collaborative tagging vocabulary), which can help translate between different users’ mental models. For instance, my tag “renewable_energy” might align with your tag “green_tech” enough that our systems recognize them as related concepts. However, pluralism is maintained: there is no enforced global taxonomy, just as there is no single global trust ranking. *Each person’s semantic graph reflects their unique perspective*, yet common patterns can be observed and leveraged by agents to facilitate communication.

The power of representing semantics in a structured way is evident from successes in natural language processing. Techniques like *Word2Vec* demonstrated that by processing large amounts of text, algorithms can embed words in a vector space such that **words with similar context end up near each other in meaning** ([Demystifying Word Vectors - DEV Community](https://dev.to/jbahire/demystifying-word-vectors-50pj#:~:text=Demystifying%20Word%20Vectors%20,The%20context)). In other words, *“you shall know a word by the company it keeps”* – distributional similarity reveals semantic relationships. By analogy, in our system one might say *“you shall know a person or piece of information by the tags it keeps”*. If two articles frequently share many tags in common across many users’ graphs, they likely cover related topics. If two users tag things similarly, they might have a shared perspective or expertise. The personal semantic graphs could be used to compute embeddings or similarity measures, enabling AI to do smart matching and recommendation without relying on opaque corporate algorithms. And because tags are user-defined, this approach avoids the brittleness of purely top-down ontologies while still adding structure to the information landscape.

In sum, semantic tagging in the Cognitive Sovereignty Mesh serves to *externalize mental models into a legible form*. It extends the mind into a personal knowledge base that is interoperable with software agents. It also creates a **semantic layer of the web** driven by users, complementing the identity and trust layers. Each tag, link, and weight is a piece of cognitive metadata that contributes to making the system intelligible and navigable – not just for the individual user, but in aggregate for communities of interest.

### Pluralism, Legibility, and Cognitive Sovereignty as Guiding Values  
Underpinning the technical design are core **values** intended to ensure the system truly empowers its users. *Pluralism* is the acceptance and support of many coexisting perspectives. The Cognitive Sovereignty Mesh is explicitly pluralistic: it does not impose a single way of categorizing or valuing information. Instead, it provides the scaffolding for each individual (or community) to express their own worldview – through their choice of tags, trust connections, and agent behaviors – and to share or combine these with others as they see fit. This echoes ideas of cognitive pluralism and “subjective webs” discussed in decentralized web communities. Rather than converge on one truth, the system enables a tapestry of *subjective truths* that can nonetheless interoperate. This is crucial for a healthy epistemic ecosystem in a diverse society; **no central authority dictates what is true or trustworthy**, and minority viewpoints can exist and find their networks, while blatantly false information is naturally constrained by lack of trust pathways.

*Legibility* means the system’s operations should be transparent and understandable to its users. Modern AI and social networks often function as black boxes – users see the outputs (recommendations, feed rankings) but not the reasoning. This can undermine trust and agency, as people cannot easily tell why they are seeing something or how to correct the system’s course. In our approach, legibility is a priority: the constructs of identity, tagging, and trust are all visible and inspectable. A user can trace *why* a piece of content was prioritized – e.g., it was posted by Carol, whom you trust 0.7 (directly or via Bob’s 0.9 trust in Carol), and it matches several of your high-weight tags. The cognitive structures (graphs and tags) function as an audit trail for information flow. Even the AI agents (discussed later) should be able to explain their suggestions in terms of a user’s own stored preferences or rules. In short, legibility counters the risk that sophisticated AI+social systems become “incomprehensible high-tech overlords.” Every recommendation or decision can, at least in principle, be translated back into human-understandable terms (tags, trust links, etc.), because those are the terms the user provided. This not only increases user confidence but also makes the system **debuggable and governable** by its users.

Finally, **cognitive sovereignty** is the overarching value tying everything together. *Cognitive sovereignty* refers to an individual’s autonomy over their own mind and decision-making processes in the digital sphere – the freedom to shape one’s understanding of the world without undue manipulation ([Maintaining Cognitive Sovereignty in the Age of LLMs | Medium](https://eamonnmag.medium.com/maintaining-cognitive-sovereignty-in-the-age-of-llms-bcbad3344960?source=rss------technology-5#:~:text=Maintaining%20Cognitive%20Sovereignty%20in%20the,It%20encompasses)). In practical terms, it means users control their identity (so they cannot be “erased” or impersonated without their consent), their data (what they share or keep private), their attention (what information reaches them), and their cognitive tools (how AI assists them). The design of the system aims to maximize this personal agency. Where today a user’s attention is often hijacked by advertiser-driven feeds, a cognitively sovereign system ensures the user (with help from their chosen agents) *allocates their attention according to their own priorities*. Where today one’s digital identity can be suspended by a platform, here the identity lives independently and cannot be deleted – only the user can choose whom to interact with or not. Cognitive sovereignty also encompasses privacy and consent: trust links and tags can be kept private or shared selectively; you might maintain a personal journal of tags that only your AI sees, separate from the public tags you share with friends, for example. The user’s mind is at the center, with the infrastructure serving as an extension of it rather than a constraint upon it.

These values align closely with those articulated by the early *Augmented Social Network (ASN)* proposal. The ASN paper envisioned an Internet architecture that explicitly *built in identity and trust to better connect people with shared interests and revitalize civil society* ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=Could%20the%20next%20generation%20of,to%20take%20care%20of%20themselves)) ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=This%20paper%20proposes%20the%20creation,to%20better%20engage%20in%20the)). It emphasized persistent identity in support of the commons, and the ability for citizens to self-organize across networks – essentially a form of digital pluralism and empowerment. It also called for **open standards and transparency** so that the system’s trustworthiness could be scrutinized ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=)). Our Cognitive Sovereignty Mesh can be seen as a modern continuation of that vision, updated with contemporary technology (like DHTs, cryptocurrency, and AI) and extending it into the cognitive realm (semantic graphs and personal AI). Pluralism, legibility, and cognitive sovereignty are not just abstract ideals; they are design constraints that ensure the resulting ecosystem is one where individuals and communities can thrive on their own terms. In the next section, we translate these principles into a concrete system architecture.

## Architecture of the Cognitive Sovereignty Mesh

### Pubky and the Self-Sovereign Identity Layer  
At the base of the mesh is the **identity layer**, anchored by public key cryptography. We use *Pubky* (or similar decentralized PKI systems) as the backbone for identity. Each user possesses one or more keypairs; the public key serves as their address on the network, and the private key allows them to sign statements (authenticating their identity, tagging content, issuing trust attestations, etc.). Through Pubky’s use of the Mainline DHT, a public key can be associated with a set of data records (PKARR) discoverable globally ([Mainline DHT — Censorship Resistance Explained | by Severin Alexander Bühler | Pubky | Dec, 2024 | Medium | Pubky](https://medium.com/pubky/mainline-dht-censorship-explained-b62763db39cb#:~:text=At%20Synonym%2C%20we%20created%20PKARR,to%20censorship%20and%20central%20control)). For example, a user’s profile (name, avatar, bio) and pointers to their content or home server can be stored as a “Public Key Domain” record, retrievable from the DHT by querying the key’s hash. This functions like a decentralized profile directory or DNS: given someone’s key (which might be represented in a user-friendly way, like an npub or other encoding), anyone can lookup and retrieve the associated data without needing a central server ([Add Pubky Integration · Issue #1548 · nostr-protocol/nips · GitHub](https://github.com/nostr-protocol/nips/issues/1548#:~:text=Loading)).

The system ensures **atomic ownership** of identity in the sense that the binding between a key and a record is secured by cryptographic proofs. Only the holder of the private key can update their records, and the DHT replication guarantees that records, once published, are available from multiple nodes. This confers strong *censorship resistance*: an adversary cannot easily expunge a user’s presence, since there is no single point to attack. It also decouples identity from any specific application. Users could seamlessly move between social applications, forums, or marketplaces, logging in with the same key and having their reputation and social connections already established via their trust graph and tags. The experience might be akin to an Internet where your *browser + key* is your primary gateway, carrying “you” with it, and websites are just views on the shared substrate rather than silos. Indeed, one Pubky advocate describes that if a user is banned on one server, they could simply “pick up again right where [they] left off from another server” because their identity and data are self-sovereign ([Introducing Pubky, a comprehensive solution for fixing the web, from Synonym \ stacker news ~nostr](https://stacker.news/items/741757#:~:text=On%20the%20tech%20side%2C%20you,left%20off%20from%20another%20server)).

The identity layer also enables global **interoperability**. Just as email or phone networks allow any provider to reach any other via common protocols, a key-based identity allows any two people or services on the mesh to identify and communicate with each other given only their pubkeys (plus perhaps DHT bootstrap info). Nostr, a rising decentralized social protocol, similarly uses keys as identities – and efforts have been made to integrate Nostr with Pubky’s discovery mechanisms ([Add Pubky Integration · Issue #1548 · nostr-protocol/nips · GitHub](https://github.com/nostr-protocol/nips/issues/1548#:~:text=It%20has%20also%20been%20integrated,tracking%20DNS%20server)). By using keys as a unifying identity, the mesh can interface with other systems (Bitcoin addresses, Nostr pubkeys, DIDs from other networks) relatively easily – they’re all just keys that can be bridged via attestations or dual-registrations in the DHT. 

On top of this identity layer, we can implement *authentication and encryption* for private communications. Public keys can serve as encryption identities as well, allowing users to exchange messages securely end-to-end. This is important when trust and tag data might be sensitive – e.g., you might privately tag a piece of content as “disturbing” or give a frank trust rating to a colleague; encryption ensures such personal notes are only seen by intended parties (perhaps only you and your AI, or a small circle). 

In summary, **Pubky provides the “nervous system” of the mesh**: it is the always-on, background mechanism by which identities are located and verified, and through which any piece of data or content can be attached to an identity in an uncensorable way. With this in place, we can build the higher layers of semantics and trust on a solid foundation of self-sovereignty and connectivity.

### Semantic Tagging Infrastructure  
Layered above identity is the **semantic layer**, where all the tagging and knowledge graph activity takes place. Practically, this could be implemented as a combination of personal databases plus a protocol for sharing and synchronizing tags. For instance, each user might maintain a local *Social Semantic Graph* (SSG) – a store containing nodes for entities (people, content items, concepts) and labeled edges representing tag relationships or trust relationships. This SSG could be stored in a secure personal datastore (perhaps using a local-first syncing database or even embedded in a Bitcoin-based storage if small enough). When a user tags something or updates a rating, these changes are signed by their key and optionally published to others (maybe via the DHT or via a relay akin to Nostr relays, but with semantic data). 

To illustrate, suppose Alice reads an article “Climate Trends 2025” and tags it with: *topic: climate_science*, *quality: high*, *stance: aligns_with_consensus*. These tags and the association to the article (which might itself be identified by a content hash or a link) are recorded in Alice’s SSG. If Alice has set her preferences to share certain tags publicly (say topic tags and quality ratings), then her system will publish an attestation: “PubKey_A tags Content_X with (topic=climate_science, quality=high)” to the network. Interested peers (those who follow Alice or subscribe to topics she curates) can receive this attestation and choose to integrate it into their view. In essence, every tag can be thought of as a tiny **knowledge assertion** made by an identity about an object. The collection of these assertions forms a distributed knowledge base, filtered through personal trust. This resembles the vision of the Semantic Web but here it’s highly personalized and woven into a trust framework, avoiding the need for one universal ontology.

The tagging system should support **ontology-making on the fly**. Users can invent new tags at will; tags are identified by strings or URIs and can be linked to each other (e.g., you might link *climate_science* tag as a subset of *environment* tag in your graph, or mark *satire* as a kind of *humor* tag). Over time, commonly used tags will naturally interlink as people map their tags to others’ equivalent tags (a bit like how folksonomies converge). The system might assist by suggesting tag mappings if it notices strong correlations (with AI help). Crucially, no central authority mandates a taxonomy – the ontology is emergent and plural. 

Tags can also apply to people (identity pubkeys). For example, you might tag Bob’s identity with *expert: cryptography* or *friend* or *political_leaning: libertarian*. This mingling of *concept tags* and *social tags* in one graph is powerful: it means your system can reason like “Bob is tagged as expert in cryptography (by me and perhaps others I trust); this new article on cryptography is tagged by Bob as high-quality; therefore I should pay attention to it.” It creates a *contextual trust*. In traditional Web of Trust, you either trust someone generally or not. Here, you can trust someone in certain domains based on tags. The combination of “trust edge + topic tag” refines the meaning: Bob is trusted *as a curator of cryptography content*, but maybe not for other topics.

The data model for these tags and graphs could be represented in JSON-LD or some graph format to ease interoperability. Each assertion would include the issuer’s pubkey, the subject (could be another pubkey, or a content hash/ID, or even a literal concept), the predicate (tag name or relationship type), and optionally a value/weight. Because each assertion is signed, they are non-repudiable and attributable. Others can build services indexing these assertions, enabling search like “find content that a pubkey I trust tagged with X”. The openness of the tags (with user consent) could also foster **community-driven knowledge bases** – imagine a group of climate scientists all tagging important datasets and papers; their combined graph (accessible via following all their keys) could act as a high-quality repository for others. This could supplement or even disrupt traditional centralized platforms (like StackExchange or Reddit) by providing an *overlay of meaning* on the web that is driven by expert communities rather than platform owners.

### Personal Trust Graph Implementation and Use  
The **trust graph** data (who trusts whom and how much) can be managed similarly to tags. In fact, a trust rating is essentially a special kind of tag: an assertion by you about another’s identity, with the predicate “trust” and a weight. The difference is that these trust edges are likely mostly private or shared only with close contacts, because broadcasting exactly how much you trust everyone could be socially sensitive. However, some users or organizations might choose to publish trust attestations publicly – for instance, a well-known expert might publicly vouch for another expert’s credibility. In any case, each user’s client software will maintain a trust score database for other pubkeys. 

When it comes to using the trust graph for decision-making, we can draw on algorithms like *flow models* or *iterative propagation*. For example, a simple rule could be: “for each new content item or tag assertion I receive, compute a credibility score by looking at all paths of trust from me to the source of that assertion, discounting each hop by a factor, and summing the contributions.” This is analogous to personalized PageRank on the trust graph, where the personalization vector is the user’s direct trust assignments. The effect is that content from a user whom I directly trust with weight 1.0 arrives with full strength; content from someone two hops away (I trust A who trusts B who posted content) might have a reduced weight (say 0.8 * 0.7 = 0.56 if those are the hop weights). Content from a stranger with no trust path is either not shown or shown with a very low default weight. Over time, if I notice I’m missing useful info, I might add a trust link or increase weights; if I see unwanted info leaking through via someone, I might reduce or cut that trust link. In effect, *users train their own trust filter* the way one might train a Bayesian spam filter, but in a human-understandable way.

Technically, trust computation can happen client-side for full sovereignty (the user’s app pulls in all needed trust attestations from those they follow and calculates scores). There could also be volunteer or distributed services to crunch larger trust graphs for suggestions (e.g., “people similar to you trust X that you haven’t rated; would you like to trust X?”). We should note that because trust is personal, attempts to aggregate it into one global metric can be contentious – the mesh should avoid a single “reputation score” that applies universally. Instead, *trust remains a vector relative to each person*. However, communities could define shared trust policies if they want a group consensus score (similar to how some forums have moderators or collective voting – here it could be implemented via a communal trust graph that members update by consensus).

One concrete application of the trust graph is **decentralized moderation**. In conventional social networks, moderation is either centralized (platform moderators) or at best crowd-sourced in a global way (everyone can flag content to be removed for all). In our system, moderation is individualized: if spam or abuse comes in, most users won’t see it in the first place, because the source has no trust path to them. Even if it does appear, one user blocking or distrustful-tagging that source will remove it for them, and possibly for others in their trust network who take their cues. This is a *subjective moderation model*, which some decentralized networks (like Secure Scuttlebutt and Nostr) are also exploring. It could prevent large-scale harassment or misinformation campaigns from achieving virality, because they cannot easily bridge into trust networks unless they somehow fool trusted nodes – which would quickly be corrected as soon as the deception is revealed, by withdrawing trust. 

The trust graph can also integrate with the **identity layer for verification**. For example, to avoid sybil attacks (fake identities), you may require that any new identity that interacts with you comes with at least one or two introductions from keys you trust (analogous to needing signatures on a PGP key to consider it valid ([PGP Web of Trust: Delegated Trust and Keyservers - Linux Foundation](https://www.linuxfoundation.org/blog/blog/pgp-web-of-trust-delegated-trust-and-keyservers#:~:text=Trust%20can%20be%20full%20or,marginally%20trusted%20keys%20to))). This naturally incorporates identity verification into social interaction: if a stranger’s key is not known, their content is deprioritized until they gain trust endorsements. This incentivizes good behavior and contribution to gain trust in a bottom-up manner, rather than relying on platform-enforced “verification badges.” 

### Trust-Based Peer Credit and Atomic Settlement  
Moving beyond information sharing, the Cognitive Sovereignty Mesh contemplates an integrated **economic layer** where trust translates into peer-to-peer credit. This concept, sometimes referred to as *trust-lines* or social credit circuits, is not entirely new – it harkens back to early digital currency ideas like the original Ripple system (circa 2004, not to be confused with the later XRP cryptocurrency). The idea is simple: if Alice and Bob trust each other, Bob might be willing to accept an IOU from Alice as payment, because he trusts that Alice will settle the debt later. If Bob then needs to pay Charlie, and Charlie trusts Bob, Bob could pass along Alice’s IOU to Charlie (in effect, Charlie now has an IOU from Alice via Bob’s endorsement). In this way, chains of trust can facilitate exchange of value, **forming a currency backed by social trust**. Eventually, these IOUs can be settled by reconciling balances, ideally anchored to a hard currency like Bitcoin for final settlement (hence “atomic” in the sense of finality when needed).

In our mesh, every trust relationship could double as a **line of credit** of a sort. If Alice trusts Bob with weight 0.8, perhaps that translates to some maximum value Alice would extend or accept in transactions with Bob. Communities of trust could develop their own token or credit systems where, say, a local group issues a token that members accept because they trust the issuer’s promise to redeem it for goods or services. This resonates with Synonym’s concept of an “Atomic Economy” which envisions a reputation-aware circular economy that obsoletes traditional banks ([Bitcoin Company Synonym Launches Architecture For A Self-Sovereign Economy](https://bitcoinmagazine.com/business/synonym-launches-architecture-for-self-sovereign-economy-around-bitcoin#:~:text=%E2%80%9CThe%20idea%20is%20to%20actually,%E2%80%9D)). In an Atomic Economy, minimal conversion and maximal local trust create a highly efficient social economy ([Bitcoin Company Synonym Launches Architecture For A Self-Sovereign Economy](https://bitcoinmagazine.com/business/synonym-launches-architecture-for-self-sovereign-economy-around-bitcoin#:~:text=%E2%80%9CThe%20idea%20is%20to%20actually,%E2%80%9D)). The *Slashtags* protocol (from Synonym) already hints at enabling people and businesses to issue tokens (IOUs, vouchers, etc.) and let the Web of Trust determine their credibility ([Bitcoin Company Synonym Launches Architecture For A Self-Sovereign Economy](https://bitcoinmagazine.com/business/synonym-launches-architecture-for-self-sovereign-economy-around-bitcoin#:~:text=unscalable%20blockchain%20bullshit%2C%E2%80%9D%20he%20said,%E2%80%9D)). For example, a bookstore could issue “book tokens” (promises for a book) and customers who trust that bookstore (and see many others trust it) might accept those tokens, perhaps even trading them. Because all these issuers and users are on the identity+trust network, *marketplaces of credit* can form without a central clearinghouse – trust itself is the ledger.

However, to avoid endless accumulation of IOUs or potential default cascades, *settlement* is needed. Here the integration with Bitcoin and Lightning Network is advantageous. Bitcoin provides a neutral, permissionless settlement layer; Lightning provides fast, low-fee transfers. If Alice has accumulated a large credit from Bob (meaning Bob owes her), they can settle by Bob sending Alice a Bitcoin (or Lightning) payment to clear the slate. Smart contracts or business rules could trigger such settlements at certain thresholds, making it mostly automatic. This way, the system harnesses the efficiency of trust (most day-to-day transactions can be done via simple social credit, no bank required) while still anchoring to a reliable form of value for finality. It’s *trust-based atomicity*: trust handles the frequent interactions, and when needed, an atomic (indivisible, final) payment happens to reconcile trust accounts.

One can think of this as **local currencies or mutual credit** systems living inside the trust mesh. Historically, mutual credit circles (like LETS systems) suffered from limited reach and trust issues. But with the mesh, if two separate trust-circles overlap via a trust connection, value can flow between them. The old vision from the Augmented Social Network commentary imagined that contributions in one online community could be valued in another via a “trusted exchange system” linking social capital across networks ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=within%20a%20market%20environment%29,as%20your%20recent%20thoughts%20about)). The trust-weighted credit is exactly such an exchange: if Community A trusts some members of Community B, they might honor B’s credits to a degree, allowing inter-community trade of favors or knowledge. Over time, this could **decentralize economic power**, reducing reliance on large financial intermediaries. Participants effectively become their own micro-bankers, with reputation as collateral.

One challenge is preventing abuse: someone could in theory accrue a lot of credit then disappear (default). Trust networks mitigate this by quickly ostracizing defaulters – their trust rating would plummet everywhere via shared attestations of the default. Moreover, since identities are persistent and tied to possible legal identity (if users choose to link them), defaulters face social and reputational costs. In high-stakes cases, people may still require legal contracts, but for everyday small transactions, social enforcement might suffice. The mesh’s **legibility** helps here: if you are considering accepting a credit token from an unknown issuer, you can examine the trust graph and see, for instance, that three people you trust fully have all trusted this issuer (perhaps akin to needing multiple marginal trust signatures in PGP to trust a key ([PGP Web of Trust: Delegated Trust and Keyservers - Linux Foundation](https://www.linuxfoundation.org/blog/blog/pgp-web-of-trust-delegated-trust-and-keyservers#:~:text=PGP%20Web%20of%20Trust%3A%20Delegated,marginally%20trusted%20keys%20to))). That could give you confidence to accept it. If those trust links weren’t visible, you’d be flying blind, but legibility means you see the social proof backing the credit.

In summary, adding a **trust-based economic layer** turns the Cognitive Sovereignty Mesh into not just a knowledge network but also a transactional network – a **social marketplace** where reputation is directly tied to economic capacity. It aligns economic incentives with trust and good behavior: reliable, community-serving actors gain trust and thus can trade more easily or issue valued tokens; scammers quickly lose trust and thus lose the ability to transact. This flips the current paradigm where bad actors can often slip through cracks or rely on centralized payment processors that don’t know the community context. Here, *the community is the processor*. By proposing to integrate this with Bitcoin (for final settlement) and Lightning, we also ensure that this system doesn’t require a bespoke blockchain or currency for every community (avoiding the fragmentation and speculation issues seen in many “Web3” attempts). Instead, it leverages the sound money of Bitcoin as the backbone and uses trust as the “soft tissue” connecting everything.

### AI Agents Aligned with Personal Semantic Graphs  
A standout feature of the Cognitive Sovereignty Mesh is how it envisions **AI agents** functioning within it. In today’s platforms, AI is often used to maximize engagement (e.g. recommendation algorithms) or as generic assistants (like large language models that answer questions with no knowledge of the user). Here, we invert that relationship: AI becomes *subservient to the user’s goals and perspective*, and it is trained/adjusted on the user’s own semantic and trust data. We can call these agents **Personal Cognitive Agents**. 

Each user could have an AI model (or several specialized models) that are co-trained on their data. “Co-trained” could mean fine-tuned on a corpus of the user’s tags, notes, and interaction history, or even continually learning from feedback in the form of the user’s tagging and trust adjustments. For example, if your agent suggests an article to you and you mark it as “low quality” and perhaps tag the source as “unreliable”, that feedback should update the agent’s internal model so it avoids similar suggestions in the future. Over time, the agent effectively **learns your mental model** – it builds an internal representation of what you believe is important, true, or interesting. This personal alignment is crucial for *cognitive sovereignty*: rather than a one-size-fits-all AI imposing some average worldview, you get an AI that reflects *your* worldview (while still having the capacity to surprise or challenge you as you permit).

The AI can utilize the **personal semantic graph** as a knowledge base. With techniques like retrieval-augmented generation, a language model could query your graph for relevant facts or past opinions you’ve expressed before formulating an answer. For instance, if you ask your agent “Should I trust the health advice in this article?”, the agent can check your trust graph to see if the author is someone you (or your trusted friends) have vetted, and check your semantic tags to see if the content aligns with what you consider credible sources (maybe you have tagged certain medical journals as highly reliable). It could then respond: “The article is written by Dr. Smith. You have not encountered Dr. Smith before, but Dr. Jones (whom you trust 0.9 in health matters) has cited Smith’s research positively ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)). The article’s claims mostly align with sources you tagged as *evidence-based*. So, it appears reasonably trustworthy, though you might want to verify specific claims.” This kind of answer is far more useful than a generic summary because it is *grounded in your personal trust network and knowledge tags*. It’s like asking a well-informed assistant who knows not just general facts but also knows *what you know* and *what you care about*.

Co-training AI on personal data also provides a path for AI alignment on a broader scale. One of the great challenges in AI ethics is how to align AI with human values when humanity’s values are diverse and context-dependent. A top-down approach (finding one objective function for all) is likely impossible. But if each AI is aligned to an individual or a community, then each AI only needs to reflect the values of its local context. This creates a mosaic of aligned AIs, which is more manageable. As long as individuals have sovereignty, their AI will not go rogue in ways they wouldn’t agree with, because its training incentives are directly tied to the user’s feedback and data. Additionally, multiple personal AIs can collaborate or negotiate, each representing their user’s viewpoint – a kind of *plurality of AI* instead of a monolithic AI overlord. This resonates with concepts of *cognitive pluralism* in AI ([Cognitive Sovereignty & AI: The Next Evolution in Intelligence](https://medium.com/@info_23172/cognitive-sovereignty-ai-the-next-evolution-in-intelligence-2ed7418eee00#:~:text=Cognitive%20Sovereignty%20%26%20AI%3A%20The,without%20ideological%20distortion%2C%20and)), suggesting that fostering many intelligences aligned with respective human perspectives could be safer and more just than aiming for one unified intelligence.

Imagine, for example, a future internet forum that is actually a meeting of AIs representing their users’ arguments. Each AI might present its user’s position on a topic (having been trained on that user’s posts, sources, and beliefs), and they might debate or try to reach consensus, while the human users oversee or step in. The debate would be constrained by the values imparted by each user – so if your value is to remain civil, your AI will remain civil. If your value is evidence-based reasoning, your AI will emphasize that. The outcome could then be summarized to the humans, who ultimately decide. This scenario illustrates how *AI agents can amplify human cognition and social discourse without supplanting it*. They become tools for filtering, translating, and negotiating information in accordance with human-set parameters.

From an implementation standpoint, these personal AIs could be local (running on personal devices for privacy) or cloud-hosted but under the user’s control (perhaps as a paid service the user can trust, or as part of a decentralized AI network). They would ingest the user’s semantic and trust graph regularly. Large language models today can be fine-tuned or at least guided via prompts and retrieval; even if not fully retrained for each user, a combination of clever prompting with the user’s data and lightweight fine-tuning (like LoRA, adapters) might suffice to *specialize general models into personal aides*. Crucially, the model’s alignment should be testable by the user: you might ask it, “What do I tend to think about topic X?” or “What would I say in situation Y?” to see if it has modeled you correctly. If not, you correct it (like one corrects a human assistant or a new team member). Over time, a high-trust relationship can form between user and agent – almost a symbiotic extended mind relationship.

The AI agents also serve another function: **maintaining cognitive bandwidth** for the user. With so much data, even with trust filters, there is still a lot of relevant information that could demand attention. The personal AI can triage and summarize, acting as an intelligent filter that further refines what reaches conscious human attention. The difference from today’s feed algorithms is again the criteria: instead of “maximize clicks or watchtime,” the criteria might be “maximize user’s stated goals.” If your goal is to stay informed on certain topics in minimal time, your agent will prioritize those and even summarize them for you, possibly hiding less critical details unless you ask. If another goal is to expose you to a variety of viewpoints (because you’ve indicated a value for pluralism), it might intentionally include a well-argued piece from an author you haven’t tagged as trustworthy but that many people outside your circle respect – and it will tell you it’s doing so, with rationale. In doing this, the agent *respects your cognitive sovereignty but also helps you exercise it effectively*. It prevents information fatigue by handling the first pass of filtering.

Finally, having AI deeply integrated with the trust/tag framework introduces a powerful feedback loop: the more you use and correct your AI, the more data (tags, ratings) it generates, which feeds back into your graph. For instance, you might have a conversation with your agent about an article, and the agent could propose a tag (“It sounds like you found this article speculative – shall I tag it as *unconfirmed*?”). If you agree, that tag is added. Thus the AI becomes a collaborator in building your externalized knowledge. This addresses a common problem where busy users might not manually tag everything; the AI can infer and suggest tags based on the user’s behavior or remarks. Over time, this could semi-automate the growth of one’s personal semantic graph (with the user always in the loop to approve or adjust – maintaining legibility and control).

In conclusion, **personal AI agents in the mesh act as amplifiers and guardians of the user’s cognition**, trained on the user’s semantic and trust landscape. They ensure that as the world’s knowledge and interactions scale up, each individual’s ability to cope and thrive scales up too, by outsourcing mechanical aspects of cognition to aligned helpers. This marries the old dream of AI as *augmentative intelligence* with the new possibility of decentralized personal data – delivering AI that is on *your* side, because it was literally built from *your* mind’s external footprint.

### Mesh Connectivity and Bandwidth Economics (Revisited)  
The term **“bandwidth economics”** has been used informally to describe how individuals must allocate their limited attention (cognitive bandwidth) in the face of limitless information. In the context of Pubky and our mesh, it refers to optimizing the flow of information so that one’s finite attention is spent on high-value content. In traditional networking, bandwidth economics might refer to efficiently using network capacity; by analogy, here it’s about efficiently using *mental capacity*. As Herbert Simon famously noted in 1971, *“a wealth of information creates a poverty of attention,”* necessitating strategies to allocate attention efficiently ([Quote by Herbert A. Simon: “In an information-rich world, the wealth ...](https://www.goodreads.com/quotes/8502027-in-an-information-rich-world-the-wealth-of-information-means-a#:~:text=,the%20overabundance%20of%20information)). Our system of trust filters and personal AIs is essentially an answer to that challenge: it is an attention-allocation mechanism under the user’s control.

However, the phrase “bandwidth economics” is not commonly found in academic literature on attention or information management. To align with existing concepts, we can reframe this idea as the **Economics of Attention** or **Cognitive Load Management**. The mesh provides tools for *attention autonomy*: users consciously decide, assisted by their agents, where to focus or what to ignore. Traditional attention economy (as practiced by ad-driven platforms) works against the user – it’s about capturing attention by any means. Here we propose a *sovereign attention economy*, where each user is like the “central bank” of their own attention, setting interest rates (priorities) on what is worth their time. The currency in this economy is points of trust and relevance, and the “market mechanism” is the decentralized negotiation between your preferences and the incoming signals from others. If something or someone doesn’t meet your threshold, they don’t get your attention “budget.”

In more concrete terms, the mesh can reduce *information transaction costs*. For example, instead of spending an hour searching for a reliable source on a topic (wasting cognitive bandwidth sifting through noise), you could query your network: your agent finds that among the people you trust, 5 have posted about this topic and 3 of those posts were tagged as high-quality by people you also trust. So it presents those to you first. The time and mental effort saved is enormous – this is the economic gain of a well-structured epistemic substrate. It also means you are less likely to fall prey to misinformation simply because you ran out of time to research; your mesh has effectively *priced bad information out of your market* by not giving it the scarce resource of your attention unless it earns its way via your trust network.

To refine the notion and fit Pubky’s framework, we might use terms like **“trust-weighted attention”** or **“relevance-guided bandwidth”**. These emphasize that it’s not raw bandwidth being allocated randomly, but bandwidth guided by trust and semantic relevance. In essence, every user has a limited attention bandwidth each day, and the mesh attempts to allocate that bandwidth in line with the user’s values and needs (much like an investor allocates capital in line with a strategy). Because this is a new kind of self-regulating system, we could also term it **“cognitive bandwidth economy”** to capture both the scarcity (bandwidth) and the structured decision-making (economy). 

Under the hood, one could implement a sort of personal attention budget algorithm. For instance, a user might specify: “At most 30 minutes per day on news, 15 on community discussions, 2 hours on work-related reading, and ensure at least 15 minutes on viewpoints that challenge my own.” The agent then tries to fulfill these by selecting content via the trust/semantic mesh that fits those criteria. If “bandwidth economics” initially referred to trying to price or quantify attention in Pubky’s earlier thinking, here we refine it to *attention management guided by trust*. It aligns well with Pubky’s emphasis on user choice and high signal-to-noise, and it echoes academic discussions that have framed attention as the bottleneck of the information age ([Herbert A. Simon - Oxford Reference](https://www.oxfordreference.com/display/10.1093/acref/9780191843730.001.0001/q-oro-ed5-00019845#:~:text=Herbert%20A.%20Simon%20,%27)).

In summary, while “bandwidth economics” as a term might be uncommon, the concept it denotes is central: making sure users aren’t overloaded and that their limited cognitive bandwidth is spent optimally. We propose to frame this as part of the **cognitive sovereignty framework** – perhaps calling it *“Attentional Sovereignty”*. Just as cognitive sovereignty is about controlling one’s mind-state, attentional sovereignty is about controlling where one’s focus goes. With the Cognitive Sovereignty Mesh, attentional sovereignty is achieved by the interplay of identity (knowing who info comes from), trust (filtering sources), semantics (filtering by topic and importance), and AI assistance (automating the filtering), all working in concert. This reframing connects “bandwidth economics” to existing literature on the attention economy while highlighting Pubky’s unique approach to solving it (through decentralized trust and personalization rather than corporate curation).

## Implications and Future Trajectories

### AI Alignment through Pluralism and Personalization  
One of the profound implications of the Cognitive Sovereignty Mesh is a reimagining of **AI alignment**. In conventional terms, the AI alignment problem asks: *how do we ensure AI systems act in accordance with human values?* A difficulty is that “human values” are not monolithic; they are diverse and often conflicting. Our mesh accepts that reality via pluralism, and thereby shifts alignment to a more tractable level: align each AI with the values of the user or community it serves. This multitude of aligned AIs could collectively represent humanity’s range, rather than one AI trying to satisfy everyone. Each personal AI is effectively *an aligned sub-agent* of its user. 

In a world where such personal AIs are widespread, large-scale AI decisions could be made by federations or voting among AIs, each carrying a weighted vote according to its user (weight perhaps determined by the user’s stake or just one-person-one-vote through their agent). This could democratize AI governance. Instead of a few companies deciding how a social media algorithm works for billions, *billions of personal algorithms decide for themselves*, possibly coordinating on common standards for interoperability. If a centralized AI (say, a powerful language model API) provides a service, it might be constrained by input from personal AIs – for instance, your agent could preprocess queries to ensure the answers follow your norms, or postprocess outputs to filter out what you consider unacceptable. Essentially, personal AIs become **alignment proxies** for individuals, standing between them and any general AI services.

Cognitive pluralism also provides a safety valve: if one AI or one perspective goes awry, others remain as correctives. This is analogous to how in a diverse ecosystem, one species’ overgrowth is checked by others. For example, if a particular misinformation meme is spreading, in a centralized system it might go viral before moderators catch it. In a plural mesh, many personal AIs would likely flag it immediately (because their users have prior data indicating such patterns are false or untrustworthy), and only those in trust networks that are predisposed to it might see it – limiting its spread. And because people have different perspectives, some will catch errors that others miss. In aggregate, a pluralistic network with individuals in control might paradoxically be more robust against both falsehood and groupthink. It offers a form of *societal alignment*, emergent from numerous local alignments.

Another angle is how this affects **AI development**. Right now, AI research often tries to make one model that can do everything (the “generalist” approach). In our model, we would prioritize tools that allow customization, modularity, and human-in-the-loop design. An AI company might release a powerful base model, but the expectation is that it will be *woven into each user’s mesh* in a customized way. This could shift business models away from controlling end-user experience to providing good “ingredients” (models, data tools) that users themselves or open-source communities combine. There could still be collective efforts – for instance, communities might collectively train an AI on their shared knowledge graph (like a community-oriented assistant fine-tuned on that community’s archive). Those AIs would reflect community values, essentially *scaling up alignment from personal to communal level while remaining niche*, not universal.

In terms of research, this plural AI paradigm would need advances in how to efficiently adapt large models to personal data (privacy-preservingly), how to verify and explain the alignment of a model to a user, and how multiple AIs can negotiate or combine outputs. But it might avoid some of the hardest philosophical questions, because it doesn’t require settling on one moral framework for AI; it leaves that choice to users. A possible concern is echo chambers: if your AI only follows your current beliefs, does it reinforce them? We must design for *dialogue and cross-pollination*: encourage AIs to occasionally present well-supported alternative viewpoints. The mesh can facilitate that by letting users opt in to “trust bridging” – say, you designate a few people you respect even if they have different views, and allow your agent to consider their content to avoid insularity. Since the user ultimately decides those bridges, it remains sovereign choice, but tools can nudge to prevent total isolation.

Finally, aligning AI to individuals could alleviate fears of AI domination. People might be more comfortable with AI agents if they see them as *extensions of themselves* (the extended mind again) rather than an Other. It changes the narrative from “superintelligent AI vs. humans” to “my AI and me, embedded in my community, vs. problems I want to solve.” The locus of control stays with humans; AIs are amplifiers of human will. If widely adopted, this could lead to a more harmonious integration of AI into society, where *AIs empower cognitive sovereignty instead of eroding it*. It offers a hopeful path where advanced AI actually strengthens individual autonomy and diverse thought, countering the homogenizing or manipulative tendencies we fear.

### Social Organization and New Institutions  
A decentralized epistemic substrate could catalyze new forms of **social organization**. With identity, trust, and knowledge-sharing baked in at the protocol level, many functions currently performed by formal institutions might be accomplished through the mesh. We can imagine new **knowledge communities** that operate like decentralized think-tanks or universities. For example, a network of scientists on the mesh might form a *web of trust for expertise*: they tag each other’s research, trust-rate peers, and thereby create a corpus of vetted knowledge. This could serve as an alternative or supplement to traditional peer review and journal publishing. Indeed, the ASN proposal’s first objective was to enable more effective knowledge sharing across institutional boundaries ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=affinities%20or%20complimentary%20capabilities%20across,online)) – the mesh fulfills that by not being bounded by any single organization’s walls. A researcher in a developing country outside major institutions could gain reputation purely through the merit recognized by peers on the mesh, rather than needing the endorsement of a prestigious university. This could democratize expertise recognition.

In governance, consider **community decision-making**. DAOs (decentralized autonomous organizations) have tried to do on-chain voting, but often these devolve to plutocracy (vote by token stake) or are hampered by sybil attacks. A trust graph approach allows for weighted voting based on social trust – similar to liquid democracy (where you delegate votes to people you trust on each issue). The mesh could facilitate issue-based trust tagging: “I defer to Alice on environmental policy” and “I trust Bob on budget matters” and so forth. Then, when a community needs to make a decision, votes can be aggregated taking those delegations into account. This is more nuanced than one-token-one-vote, incorporating reputation and expertise. It also avoids the need to explicitly elect representatives; representation is fluid and context-specific. One could call this **epistemic democracy**, where decision influence is a function of demonstrated knowledge and trustworthiness rather than popularity or wealth alone.

New **economic institutions** may also emerge. Earlier, we described a trust-based credit economy. This could give rise to community banks or mutual aid networks built into the mesh. For example, a local group might use a shared tag “mutual_credit” to denote IOUs within the group, with rules enforced by smart contracts that integrate trust scores (someone with higher community trust might get a larger credit line by default, etc.). Over time, these could formalize into cooperative structures that are partly automated. Imagine credit unions that don’t have a brick-and-mortar presence but exist as a set of smart contracts and trust attestations among members. Because everything is transparent and member-controlled, it could significantly reduce overhead and fraud – essentially **self-governing financial micro-institutions**.

We might also see **reputation marketplaces**. If someone is very trusted for their curation (say Alice is an excellent filter for news about technology), she could monetize that by offering a feed or newsletter that others subscribe to (perhaps via micropayments or via giving her some credit in return). Because her reputation is publicly verifiable on the mesh (one can see she’s trusted by many respected parties in tech), new subscribers have confidence in her service. This could invert the influencer model – instead of chasing algorithmic virality, people build genuine expertise and get rewarded directly by peers who benefit from it. Such marketplaces would reward *quality and trustworthiness*, not just attention-grabbing. Over time, this might evolve into **guilds** or professional networks. For instance, a guild of fact-checkers might collectively tag and verify news on the mesh, earning trust that yields them micropayment income from media organizations or readers who subscribe to “mesh-verified news” feeds.

On the flip side, traditional institutions like governments and corporations would have to adapt. Governments might interface with the mesh by publishing open data and claims on it and earning a “trust rating” from citizens. A government health agency, for example, could post a health advisory which users see with a note like “You trust the agency 0.6 (based on your general trust in government sources) and additionally, 8 doctors you trust have endorsed this advisory.” If the government consistently abuses trust, people’s ratings will drop and they will lose influence – a more dynamic feedback than infrequent elections. This doesn’t replace democracy, but it adds a continuous accountability layer. 

Corporations, especially tech platforms, may find that the value is no longer in siloing user data but in contributing services to this open mesh. For example, a company might offer an AI summarization service that plugs into the mesh: it reads documents and produces tag suggestions or trustworthiness analyses. The company could charge or accept voluntary credits for this. But the raw data (the tags and trust outcomes) remain in the users’ domain. This requires a shift in mindset from owning user interactions to *competing on providing the best algorithms or experiences* on a common data plane. It’s analogous to how companies compete on the open web (anyone can publish HTML, but companies compete on designing the best websites or services) rather than owning the whole network.

This paradigm could lead to **“online citizenship”** as the ASN authors phrased it ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=identity%20that%20supports%20the%20public,for%20the%20Information%20Age)) – people participating in digital society with rights (identity ownership, privacy) and responsibilities (building trust, contributing knowledge) akin to real-world citizenship but on a global scale. Communities of practice can self-organize more easily across borders (since trust links don’t care about geography), potentially creating *new transnational institutions*. For example, an international group of climate activists could form a sort of pseudo-governmental body that tracks climate commitments and issues its own trust-mark attestation for companies or cities that meet standards. Consumers or voters worldwide could subscribe to that, effectively giving that body soft power without any legal mandate, just by virtue of earned trust.

One can also foresee **resilience in authoritarian contexts**. Where free flow of information is suppressed, a decentralized mesh that is censorship-resistant (thanks to DHT and encryption) allows citizens to maintain an underground knowledge network. The trust aspect is key there – you have to know whom to trust to not get misinformation or traps. Over time, such networks can even supplant some functions of a censored press or controlled economy, operating in parallel. It’s not a panacea, but it gives more agency than currently possible under heavy censorship.

There will be challenges, of course. Legitimacy of these new institutions might be questioned: “Who elected these trust networks to have power?” The answer is they’re elective in a different way – people *opt in* by trusting them, similar to how one chooses experts or leaders in smaller communities. There’s also the risk of **fragmentation**: if everyone has their own truth, can we agree on anything? The mesh’s pluralism does mean consensus must be built, not enforced. But common knowledge can still emerge if trust networks intersect and evidence-based tags propagate. It may actually reduce fragmentation by illuminating why differences exist (since you can trace how different tag assumptions lead to different conclusions, a legible disagreement, rather than hurling anonymous misinformation).

Lastly, this could change the nature of **platforms and companies** in the Nostr/Bitcoin ecosystem and beyond. For instance, Nostr and Pubky might converge or complement each other: Nostr providing real-time message relay, Pubky providing identity and discovery, and the trust/tag layer providing personalization. Bitcoin’s role as a settlement currency could expand as more micro-transactions and credit swaps occur via the mesh. We might even see *hybrid institutions* like *“crypto credit unions”* or *“reputation exchanges”* that use Bitcoin for value and the mesh for trust info. These would be unlike any financial institutions we have now.

In summary, the Cognitive Sovereignty Mesh can be viewed as a *civic platform* enabling bottom-up institution building. It provides the primitives (identity, trust, knowledge tagging, personal AI) and it’s up to communities to assemble those into functional organizations. Just as the early Internet didn’t predetermine Wikipedia or open-source development but enabled them, this mesh could enable new institutions of knowledge verification, economic exchange, and governance that we can only partially envision today. The key difference is that they would be **highly decentralized, transparent, and responsive to individuals**, since those are the properties baked into the substrate.

### Societal Evolution and Challenges  
If the Cognitive Sovereignty Mesh were to gain broad adoption, it could herald a significant shift in how society handles knowledge and coordination – essentially a new **knowledge age** succeeding the information age. Information would no longer be the sole commodity; *contextualized, trusted information* would be. We could see an evolution where social capital (in the form of trust and reputation) becomes as important as financial capital. This might address some problems of the current era: for example, today, disinformation and trolling are cheap – but in a trust-weighted environment, they carry a heavy cost (you burn your trust rapidly). On the positive side, good actors who currently struggle to be heard amid the noise might find they can rise more easily in their niche of trust. 

One hoped-for societal outcome is a more **resilient public sphere**. Instead of one monolithic public conversation (often manipulated by a few media or tech giants), we’d have many interlinked public spheres. *Cognitive sovereignty for the individual leads to cognitive diversity for the collective.* This diversity acts like biodiversity: it makes the whole ecosystem more resistant to viruses (e.g., misinformation “memetic viruses”). It also fosters innovation – different communities will generate different ideas, and useful ones can spread through overlapping trust networks rather than needing a single gatekeeper’s approval. It’s essentially taking the open-source model (where code from anywhere can improve the whole if it proves itself) and applying it to societal knowledge.

Education could be transformed. Instead of top-down curricula only, learners can assemble their learning journey by following trust networks of educators and experts on the mesh. Credentials may shift from diplomas to *verified skill tags* in your semantic graph, endorsed by people who observed your work. Life-long learning is enhanced as your personal knowledge graph is a living record of what you know and what you’re exploring.

Of course, there are potential pitfalls and **new failure modes** to be vigilant about. One is the formation of *echo chambers*. If not thoughtfully managed, people could theoretically cocoon themselves entirely among like-minded trusted circles and never encounter challenging information. However, the mesh at least makes that a conscious choice (unlike algorithmic bubbles that occur invisibly). And tools can encourage cross-cutting links – for example, identifying if two otherwise separate trust networks have a bridge person or common tag, and suggesting that as a point of contact. Communities could adopt norms of pluralism, explicitly tagging some content as “alternative perspective” and rewarding open-minded engagement.

Another challenge is **overwhelming complexity**. Will normal users bother tweaking all these trust and tag settings? There is a risk that only power-users benefit fully, while others stick to defaults (which might reintroduce centralized influence if default trust lists or tag vocabularies become too influential). To mitigate that, UX design and *progressive onboarding* are important. Users could start with a simple mode (maybe they choose a “trust mentor” – a person or bundle of settings to bootstrap their filter, much like one might choose an investment fund). As they grow more comfortable, they can customize more. The system could also work largely in the background with sane defaults (like initially trust people you follow or people with widely agreed good reputations) and only surface the complexities when a user wants to dig in or needs to resolve an issue.

Privacy is another concern. If all trust and tag data is shared, could that be invasive? We expect a lot of this data to be private or in small circles. Technology like zero-knowledge proofs could potentially allow usage of trust data without revealing all details (for instance, proving “at least 3 of Alice’s trusted friends vouch for X” without revealing who). Designing privacy-preserving yet transparent systems will be an ongoing tension – balancing legibility with privacy. Probably a tiered approach works: some high-level metrics can be public (like a key has at least N trusted introducers), while raw detailed opinions are private by default.

We should also consider **malicious exploitation**. Adversaries might try to infiltrate trust networks (the classic “social engineering” approach) or create sybils that slowly gain trust. The web-of-trust literature suggests requiring multiple independent trust paths to mitigate that ([Sequoia PGP Manual Pages - GitLab](https://sequoia-pgp.gitlab.io/sequoia-sq/man/sq-pki.1.html#:~:text=Sequoia%20PGP%20Manual%20Pages%20,single%20bad%20actor%20from)). The mesh’s transparency can help counter coordinated manipulation – if dozens of sockpuppet accounts all start tagging misinformation as “truth”, one can see they all stem from an isolated cluster not trusted by others. AI can assist in pattern recognition to alert users of suspicious coordination. Nonetheless, an arms race with spammers and propagandists is likely. But unlike with centralized platforms, here it’s a level playing field – users can collectively adapt their trust rules, and there’s no single target to pressure (propagandists can’t just pressure a Facebook or Twitter to allow their content, they’d have to subvert many independent users or nodes).

Over time, success of such a mesh could even shift human cognition itself – much as writing and the internet have. People might externalize more memory and decision-making, leaning on their personal AI, and focus more on higher-level judgment and creativity. This could be liberating (fewer rote tasks, more strategic thinking) or concerning (if over-reliant on AI, do we lose skills?). Ensuring *cognitive sovereignty* implies we keep the human in charge of training the AI, so hopefully we maintain a virtuous cycle where the human still learns and benefits from the AI’s help rather than becoming passive.

Finally, the widespread adoption of trust-based economies might alter macroeconomics. If local credit networks thrive, traditional banks might lose some relevance, or they might integrate with these networks (e.g., offering services to convert social credit to fiat for outsiders). The data from these networks could also provide rich insight into economic health from the ground up (since transactions and trust are recorded in the open, albeit possibly anonymized). Regulators would face novel scenarios: for instance, how to handle disputes in a system where an “IOU” might not be a legal contract but a social one. New legal frameworks might be needed to interpret digital trust attestations as evidence or agreements.

In conclusion, the Cognitive Sovereignty Mesh, as speculative as it is, sketches a future where the **power over knowledge and coordination shifts back to people and communities**, enabled by technology. It envisions a world where *truth is something we build collectively and transparently*, rather than something handed down or manipulated in shadows. Institutions become more accountable and participatory, economies become more relationship-oriented, and AI becomes a partner rather than a master. Achieving this won’t be easy – it requires not just tech but also cultural evolution, user education, and careful handling of emergent issues. Yet, the components are beginning to appear (self-sovereign IDs, decentralized networks like Nostr/Pubky, community-run instances, personal AI assistants, etc.). By bringing them together under guiding principles of pluralism, legibility, and sovereignty, we can aim to create what is essentially a **cognitive commons** – an open mesh where knowledge and trust are co-created, and every participant has a rightful place in shaping their shared reality.

## Conclusion  
We have outlined the vision of a **Cognitive Sovereignty Mesh**: a decentralized cognitive infrastructure that re-integrates identity, trust, semantic meaning, and AI assistance in service of individual and community empowerment. Starting from foundational ideas of the extended mind and webs of trust, we built up the design of a system where user-controlled public key identities form the backbone for sharing data and attestations, personal semantic tagging externalizes each user’s mental models, and weighted trust graphs allow for subjective yet structured filtering of information. Layered on top, personal AI agents leverage these graphs to align with their users’ values and preferences, acting as extensions of thought and guardians of attention. The interplay of these elements – identities, tags, trust, AI – creates an epistemic substrate that is vastly different from the status quo: it is peer-to-peer, pluralistic, and user-sovereign by construction.

We situated this framework in the context of existing literature and precursors. The concept draws inspiration from *Augmented Social Networks* ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=This%20paper%20proposes%20the%20creation,to%20better%20engage%20in%20the)) and *Subjective Web of Trust* models ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)), affirming earlier predictions that the Internet’s next evolution would involve baking identity and trust into its core. It updates those visions with modern tools like DHT-based identity (Pubky) ([Add Pubky Integration · Issue #1548 · nostr-protocol/nips · GitHub](https://github.com/nostr-protocol/nips/issues/1548#:~:text=It%20has%20also%20been%20integrated,tracking%20DNS%20server)) and learning algorithms, showing how they can fulfill long-standing goals of enhancing knowledge sharing and civic collaboration. We also discussed how to refine notions like *“bandwidth economics”* into the language of the attention economy and cognitive load management, ensuring the framework aligns with known concepts while extending them. By renaming that idea as *sovereign attention management* and grounding it in Herbert Simon’s insight on attention scarcity ([Herbert A. Simon - Oxford Reference](https://www.oxfordreference.com/display/10.1093/acref/9780191843730.001.0001/q-oro-ed5-00019845#:~:text=Herbert%20A.%20Simon%20,%27)), we placed an ostensibly novel term into a continuum of research on information overload and human-computer interaction.

The **implications** of the Cognitive Sovereignty Mesh are far-reaching. On the technical front, it suggests new directions for building social software – moving from platform-centric designs to protocol-centric, user-owned designs. On the social front, it holds promise for tackling issues like misinformation, echo chambers, and the erosion of trust in institutions by offering an alternative mode of curating truth: one that is transparent and bottom-up. We saw how AI alignment might be rethought in this pluralistic context, potentially alleviating some global risks by distributing the problem into many local alignments. We also ventured into how economic and governance structures could evolve, envisioning reputational economies and decentralized decision-making processes that augment or replace traditional centralized ones. These speculations illustrate both the transformative potential of the mesh and the challenges to be addressed (from privacy to user experience to resisting adversarial attacks).

Ultimately, the Cognitive Sovereignty Mesh is an attempt to **reclaim cognitive agency** in a digital world that often undermines it. It recognizes that humans and AI will be intertwined – but it insists that this entanglement be shaped deliberately by individuals according to their own mental models, not solely by corporate or state actors. In a time when many feel technology is overwhelming or exploiting them, this framework offers a vision of technology *as an empowering ally*: a network that extends our minds and communities without subsuming them. Achieving such a vision will require interdisciplinary collaboration – developers building robust decentralized protocols, civic technologists and designers ensuring accessibility and inclusiveness, AI researchers creating models that can personalize safely, and end-users themselves participating and providing feedback. It also invites further academic inquiry: for instance, formal studies of how trust networks impact information quality, or experiments on collective decision outcomes in such systems.

In closing, we stand at a juncture where the ingredients for a new web – one that prioritizes trust, meaning, and user sovereignty – are coming together. The Cognitive Sovereignty Mesh is one formulation of how they might coalesce into a coherent system. If pursued and refined, it could become the **substrate for a more sovereign and insightful digital society**, much like a neural mesh connecting independent thinkers into a greater collective intelligence. This paper has outlined the blueprint and the rationale; the next steps lie in implementation and iterative improvement, guided by the values we have articulated. As the saying goes, *“the best way to predict the future is to invent it.”* The Cognitive Sovereignty Mesh is an invitation to invent a future where our digital interactions augment our wisdom and agency, rather than detract from them – a future of true cognitive sovereignty. 

**Sources:** 

- Clark, A., & Chalmers, D. (1998). *The Extended Mind*. *Analysis, 58*(1), 7–19. (Excerpt: *"cognitive processes 'ain't all in the head.' The environment has an active role in driving cognition"* ([The Extended Mind | Books Gateway - MIT Press Direct](https://direct.mit.edu/books/edited-volume/2362/The-Extended-Mind#:~:text=The%20Extended%20Mind%20,role%20in%20driving%20cognition)))  
- Marsh, S. (1994). *Formalising Trust as a Computational Concept*. (Invented the field of Computational Trust ([Stephen (Steve) Marsh | Ontario Tech University](https://ontariotechu.ca/experts/fbit/stephen-marsh.php#:~:text=Stephen%20%28Steve%29%20Marsh%20,of%20research%20in%20computational%20trust))).  
- Searls, D. (2004). *The Subjective Web*. (Concept of a user-driven, personal perspective web, related to Vendor Relationship Management, as discussed in Doc Searls’ weblog and collaborations.)  
- PGP Web of Trust model – *Wikipedia: Web of Trust*. (Trust is decentralized; trust in keys can be full or marginal ([PGP Web of Trust: Delegated Trust and Keyservers - Linux Foundation](https://www.linuxfoundation.org/blog/blog/pgp-web-of-trust-delegated-trust-and-keyservers#:~:text=PGP%20Web%20of%20Trust%3A%20Delegated,marginally%20trusted%20keys%20to)) and multiple endorsements are needed for confidence ([Sequoia PGP Manual Pages - GitLab](https://sequoia-pgp.gitlab.io/sequoia-sq/man/sq-pki.1.html#:~:text=Sequoia%20PGP%20Manual%20Pages%20,single%20bad%20actor%20from)).)  
- Mikolov, T. et al. (2013). *Efficient Estimation of Word Representations in Vector Space*. (Introduced Word2Vec; based on the principle *“You shall know a word by the company it keeps”*, i.e. similar context implies similar meaning ([Demystifying Word Vectors - DEV Community](https://dev.to/jbahire/demystifying-word-vectors-50pj#:~:text=Demystifying%20Word%20Vectors%20,The%20context)).)  
- Jordan, K., Hauser, J., & Foster, S. (2003). *The Augmented Social Network: Building Identity and Trust into the Next-Generation Internet*. *First Monday, 8*(8). (Proposed integrating identity and trust into Internet architecture for social benefit ([Augmented Social Networks - P2P Foundation](https://wiki.p2pfoundation.net/Augmented_Social_Networks#:~:text=This%20paper%20proposes%20the%20creation,to%20better%20engage%20in%20the)).)  
- Pubky Protocol (2024). – *Synonym Ltd.* (Open protocol for per-public-key backends. Uses Mainline DHT for key-to-data mapping, allowing censorship-resistant domains per user ([Add Pubky Integration · Issue #1548 · nostr-protocol/nips · GitHub](https://github.com/nostr-protocol/nips/issues/1548#:~:text=It%20has%20also%20been%20integrated,tracking%20DNS%20server)); includes PKARR and PKDNS enhancements ([Mainline DHT — Censorship Resistance Explained | by Severin Alexander Bühler | Pubky | Dec, 2024 | Medium | Pubky](https://medium.com/pubky/mainline-dht-censorship-explained-b62763db39cb#:~:text=At%20Synonym%2C%20we%20created%20PKARR,to%20censorship%20and%20central%20control)).)  
- Carvalho, J. (2021). *Slashtags and the Atomic Economy*. – *Bitcoin Magazine*. (Web of Trust model to create user-centric networks; concept of “Atomic Economy” combining circular economy with Web of Trust ([Bitcoin Company Synonym Launches Architecture For A Self-Sovereign Economy](https://bitcoinmagazine.com/business/synonym-launches-architecture-for-self-sovereign-economy-around-bitcoin#:~:text=%E2%80%9CThe%20idea%20is%20to%20actually,%E2%80%9D)). Discusses issuing credit via tokens and using reputation to decide trust ([Bitcoin Company Synonym Launches Architecture For A Self-Sovereign Economy](https://bitcoinmagazine.com/business/synonym-launches-architecture-for-self-sovereign-economy-around-bitcoin#:~:text=unscalable%20blockchain%20bullshit%2C%E2%80%9D%20he%20said,%E2%80%9D)).)  
- Op Labs (2023). *AttestationStation and Decentralized Reputation*. – *Optimism Blog*. (Describes a decentralized attestation graph where reputation emerges from a “purely subjective web of trust,” iteratively producing a larger trust network ([Making Blockchains Human-friendly](https://blog.oplabs.co/making-blockchains-human-friendly/#:~:text=We%20can%20then%20take%20the,purely%20subjective%20web%20of%20trust)).)  
- Simon, H. (1971). *Designing Organizations for an Information-Rich World*. (Origin of the quote: *“a wealth of information creates a poverty of attention,”* highlighting attention as the scarcest resource ([Herbert A. Simon - Oxford Reference](https://www.oxfordreference.com/display/10.1093/acref/9780191843730.001.0001/q-oro-ed5-00019845#:~:text=Herbert%20A.%20Simon%20,%27)).)
